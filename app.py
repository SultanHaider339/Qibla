import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import TextLoader
from pathlib import Path
import os

# ===================== PAGE SETUP =====================
st.set_page_config(
    page_title="Ø§Ø±Ø¯Ùˆ Ø§Ø³Ù„Ø§Ù…ÛŒ Ú©ØªØ¨ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹",
    page_icon="ğŸ“–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ===================== BEAUTIFUL ISLAMIC DESIGN =====================
st.markdown("""
<style>
    .big-title {font-size: 3.8rem; color: #1e40af; text-align: center; font-weight: bold;}
    .subtitle {font-size: 1.6rem; color: #15803d; text-align: center; margin: 20px 0 40px;}
    .chat-box {background: linear-gradient(135deg, #f0fdf4, #dcfce7); border-radius: 20px; padding: 20px; box-shadow: 0 8px 25px rgba(0,0,0,0.1);}
    .source-box {background: #fefce8; padding: 12px; border-radius: 12px; border-right: 4px solid #ca8a04; margin-top: 15px; font-size: 0.92rem;}
    .footer {text-align: center; margin-top: 60px; color: #64748b; font-size: 0.95rem;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='big-title'>Ø§Ø±Ø¯Ùˆ Ø§Ø³Ù„Ø§Ù…ÛŒ Ú©ØªØ¨ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹</h1>", unsafe_allow_html=True)
st.markdown("<p class='subtitle'>ØµØ±Ù Ù…Ø³ØªÙ†Ø¯ Ú©ØªØ¨ Ø³Û’ ÙÙˆØ±ÛŒ Ø§ÙˆØ± Ø¯Ø±Ø³Øª Ø¬ÙˆØ§Ø¨Ø§Øª<br>Ú©ÙˆØ¦ÛŒ ÛÛŒÙ„ÙˆØ³ÛŒÙ†ÛŒØ´Ù† Ù†ÛÛŒÚº â€¢ Ù…Ú©Ù…Ù„ Ù¾Ø±Ø§Ø¦ÛŒÙˆÛŒÙ¹</p>", unsafe_allow_html=True)

# ===================== LOAD BOOKS (COMPLETELY HIDDEN) =====================
@st.cache_resource(show_spinner="Ú©ØªØ§Ø¨ÛŒÚº Ù„ÙˆÚˆ ÛÙˆ Ø±ÛÛŒ ÛÛŒÚº... Ú†Ù†Ø¯ Ø³ÛŒÚ©Ù†Úˆ")
def load_books():
    books_path = Path("books")
    if not books_path.exists() or len(list(books_path.iterdir())) == 0:
        return None

    docs = []
    for file in books_path.glob("*.txt"):
        loader = TextLoader(str(file), encoding="utf-8")
        docs.extend(loader.load())

    splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)
    chunks = splitter.split_documents(docs)

    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    return vectorstore

vectorstore = load_books()

if vectorstore is None:
    st.warning("Ú©ÙˆØ¦ÛŒ Ú©ØªØ§Ø¨ Ù†ÛÛŒÚº Ù…Ù„ÛŒÛ” Ù…Ø§Ù„Ú© Ø³Û’ Ø±Ø§Ø¨Ø·Û Ú©Ø±ÛŒÚºÛ”")
    st.stop()

# ===================== LLM =====================
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY")
if not GROQ_API_KEY:
    st.error("API key missing.")
    st.stop()

llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name="llama-3.1-70b-versatile",
    temperature=0.2
)

qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 4}),
    return_source_documents=True
)

# ===================== CHAT =====================
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù… ÙˆØ±Ø­Ù…Ûƒ Ø§Ù„Ù„Û ÙˆØ¨Ø±Ú©Ø§ØªÛ\n\nØ¢Ù¾ Ø§Ù¾Ù†ÛŒ Ù…Ø±Ø¶ÛŒ Ú©Ø§ Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø¯ÛŒÙ†ÛŒØŒ ÙÙ‚ÛÛŒØŒ Ø³ÛŒØ±Øª ÛŒØ§ ØªØ§Ø±ÛŒØ®ÛŒ Ø³ÙˆØ§Ù„ Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ù¾ÙˆÚ†Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ù…ÛŒÚº ØµØ±Ù Ø§Ù¾Ù†ÛŒ Ù…Ø­ÙÙˆØ¸ Ø´Ø¯Û Ù…Ø³ØªÙ†Ø¯ Ú©ØªØ§Ø¨ÙˆÚº Ø³Û’ Ø¬ÙˆØ§Ø¨ Ø¯ÙˆÚº Ú¯Ø§Û”"
    "
    }]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("ÛŒÛØ§Úº Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ù„Ú©Ú¾ÛŒÚº..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Ú©ØªØ§Ø¨ÙˆÚº Ø³Û’ ØªÙ„Ø§Ø´ Ú©Ø± Ø±ÛØ§ ÛÙˆÚº..."):
            result = qa.invoke({"query": prompt})
            answer = result["result"]

            st.markdown(answer)

            if result["source_documents"]:
                with st.expander("Ù…Ø§Ø®Ø° Ø¯ÛŒÚ©Ú¾ÛŒÚº"):
                    for i, doc in enumerate(result["source_documents"][:3], 1):
                        st.markdown(f"<div class='source-box'><strong>Ù…Ø§Ø®Ø° {i}:</strong> {doc.page_content.strip()[:400]}...</div>", 
                                  unsafe_allow_html=True)

            st.session_state.messages.append({"role": "assistant", "content": answer})

# ===================== FOOTER =====================
st.markdown("---")
st.markdown("""
<div class='footer'>
    Ù…Ú©Ù…Ù„ Ù¾Ø±Ø§Ø¦ÛŒÙˆÛŒÙ¹ â€¢ Ú©ÙˆØ¦ÛŒ ÚˆÛŒÙ¹Ø§ Ø´ÛŒØ¦Ø± Ù†ÛÛŒÚº ÛÙˆØªØ§ â€¢ Ø¨Ù†Ø§ÛŒØ§ Ú¯ÛŒØ§ Ø¢Ù¾ Ú©Û’ NLP Ù¹ÛŒÚ†Ø± Ú©ÛŒ Ø·Ø±Ù Ø³Û’<br>
    Ù…Ø§ÚˆÙ„: Llama-3.1-70B (Groq) â€¢ Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯: multilingual-e5-large
</div>
""", unsafe_allow_html=True)
